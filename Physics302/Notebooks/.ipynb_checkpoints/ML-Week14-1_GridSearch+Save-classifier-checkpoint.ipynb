{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topics\n",
    "\n",
    "## 1. Saving your trained classifier\n",
    "## 2. GridSearchCV (for facial recognition or Alak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# All imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "# -------------> The following three are new imports <------------------\n",
    "import time\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "np.set_printoptions(formatter={'float': '{:.5f}'.format})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving your classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_people.html\n",
    "\n",
    "'''\n",
    "\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size:\n",
      "targets: [5 6 3 ... 5 3 5]\n",
      "n_samples: 1288\n",
      "n_features: 1850\n",
      "n_classes: 7\n",
      "Fitting the classifier to the training set\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Breakout Solution\n",
    "\n",
    "*******************************\n",
    "For me, for the >= 70 faces set: the following takes 30-40 sec to train and the results are pretty good (alpha has to be 1e-5, and not 1e-10, not 1e-7):\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100,), activation='tanh', \\\n",
    "                    random_state=42, max_iter=100000000, learning_rate_init=0.001)\n",
    "                    \n",
    "Fitting the classifier to the training set\n",
    "Training done in 38.525s\n",
    "Training score: 0.8674948240165632\n",
    "Predicting people's names on the test set\n",
    "Validation done in 0.005s\n",
    "Test score: 0.7422360248447205\n",
    "\n",
    "+++++++++++++++++++++++++++++\n",
    "\n",
    "            \n",
    "but alpha=1e-10 takes much longer to train: 200 sec\n",
    "\n",
    "===> Consider adding progress bar\n",
    "\n",
    "\n",
    "In 2016: for iMac's in Comp Phys Lab, it takes anywhere between 10 - 50 min.\n",
    "\n",
    "\"\"\"\n",
    "# for machine learning we use the 2 data directly (as relative pixel\n",
    "# positions info is ignored by this model)\n",
    "\n",
    "X = lfw_people.data\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "# the label to predict is the id of the person\n",
    "y = lfw_people.target\n",
    "target_names = lfw_people.target_names\n",
    "n_classes = target_names.shape[0]\n",
    "\n",
    "print(\"Total dataset size:\")\n",
    "print(\"targets: {}\".format(y))\n",
    "print(\"n_samples: {:d}\".format(n_samples))\n",
    "print(\"n_features: {:d}\".format(n_features))\n",
    "print(\"n_classes: {:d}\".format(n_classes))\n",
    "\n",
    "\n",
    "# split into a training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "# Train a NN classification model\n",
    "\n",
    "print(\"Fitting the classifier to the training set\")\n",
    "t0 = time.time()\n",
    "\n",
    "# (250,) works well, too.  (80, ) too.\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100,), activation='tanh', \\\n",
    "                    random_state=42, max_iter=100000000, learning_rate_init=0.001)\n",
    "      \n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training done in {:0.3f}s\".format(time.time() - t0))\n",
    "print(\"Training score: {:.4f}\".format(clf.score(X_train, y_train)))\n",
    "\n",
    "print()\n",
    "# Quantitative evaluation of the model quality on the test set\n",
    "\n",
    "print(\"Predicting people's names on the test set\")\n",
    "t0 = time.time()\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Validation done in {:0.3f}s\".format(time.time() - t0))\n",
    "print(\"Test score: {:.4f}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Saving the classifier using pickle'''\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('clf-70min-lfw-faces.p', 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Retrieving the saved classifier\n",
    "'''\n",
    "\n",
    "with open('clf-70min-lfw-faces.p', 'rb') as f:\n",
    "    clf_saved = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions on the test set USING THE SAVED CLASSIFIER\n",
      "Test score: 0.7422\n",
      "Validation done in 0.010s\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Show the retrieved classifier works the same as before\n",
    "\n",
    "'''\n",
    "\n",
    "print(\"Making predictions on the test set USING THE SAVED CLASSIFIER:\")\n",
    "t0 = time.time()\n",
    "\n",
    "y_pred = clf_saved.predict(X_test)\n",
    "print(\"Test score: {:.4f}\".format(clf_saved.score(X_test, y_test)))\n",
    "\n",
    "print(\"Validation done in {:0.3f}s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xhuang22/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/xhuang22/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/xhuang22/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/xhuang22/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/xhuang22/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/xhuang22/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/xhuang22/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/xhuang22/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_score',\n",
       " 'param_C',\n",
       " 'param_kernel',\n",
       " 'params',\n",
       " 'rank_test_score',\n",
       " 'split0_test_score',\n",
       " 'split1_test_score',\n",
       " 'split2_test_score',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_score']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Example given in sklearn is for a different ML algorithm\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "'''\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "iris = datasets.load_iris()\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(iris.data, iris.target)\n",
    "\n",
    "\n",
    "sorted(clf.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''How to apply grid search in our case'''\n",
    "\n",
    "\n",
    "mlp_clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100,), activation='tanh', \\\n",
    "                    random_state=42, max_iter=100000000, learning_rate_init=0.001)\n",
    "\n",
    "parameters = {'learning_rate_init':[0.001, 0.005, 0.01, 0.05, 0.1, 0.5], \\\n",
    "              'hidden_layer_sizes':[(80,), (100,), (100, 20), (100, 20, 4) ]}\n",
    "\n",
    "clf = GridSearchCV(mlp_clf, parameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Week14-1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
